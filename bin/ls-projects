#!/usr/bin/env bash
# List repositories on my system using the REPO_PATH environment variable.
#
# ENVIRONMENT VARIABLES
#   REPO_PATH
#     PATH style variable pointing to code repositories or to directories which can
#     contain one or more code repositories. A trailing slash indicates a container
#     whereas the absence of one indicates a repo.
#
#     REPO_PATH can contain globs such as ~/foo/*/*/ and all of the directories
#     expanded by the glob will also be considered as potential repository
#     containers.
#
#   REPO_PATH_ALIASES
#     PATH style variable for declaring repository aliases. By default ls-projects
#     lists each project with its basename. In some cases a path derived from the
#     directory hierarchy of the project would be clearer. For example 'mohkale/dotfiles'
#     over just dotfiles. This can be achieved for ~/repos/mohkale/dotfiles by
#     setting an alias of '~/repo,'. You can also substitute a custom prefix in place
#     of this path prefix like so '~/straight/repos,straight'.

sep=':'

print_usage() {
  echo "Usage: ls-projects [-h] [-r]"
}

print_help() {
  print_usage
  cat <<-EOF

  List projects findable through REPO_PATH.

Optional arguments:
  -h  Show this help message and exit.
  -r  Recursively look for sub-projects.
  -s  Specify separator for output fields.
EOF
}

recursive=0
while getopts 'hrs:' OPTION; do
  case "$OPTION" in
    h) print_help
       exit 0 ;;
    r) recursive=1 ;;
    s) sep="$OPTARG" ;;
    \?) print_usage
        exit 1 ;;
  esac
done

# NOTE: This script can use GNU parallel or xargs, but parallel is better
# because you can spawn a single find process with multiple paths. For xargs
# each path gets it's own find process, causing a general decrease in speed
# as the number of possible repo containers increase.
batch=(  )
if command -v parallel >/dev/null 2>&1; then
    batch+=( parallel -d '\n' -X -I% --line-buffer --quote -N 1000 )
else
    batch+=( xargs -d '\n' -I% )
fi

repo_containers() {
  # Expand all the paths in REPO_PATH, including glob expansion.
  # This method also avoids duplicate paths in REPO_PATH by keeping
  # track of all the paths encountered so far.
  echo "${REPO_PATH//:/$'\n'}" |
    awk -e '!mem[$0]++' |
    while read -r it; do
      [ -z "$it" ] && continue
      for it in $it; do
        echo "$it"
      done
    done |
    perl -ne 'chomp(); if (-e $_) {print "$_\n"}'
    # filter out non-existant paths, from [[https://serverfault.com/a/609900][here]].
}

maybe_repos() {
    # we create a third file descriptor so we can partition the found
    # repo paths into container directories and repo directories. Repo
    # directories are sent straight to &3, others are piped to a find
    # process which outputs the repo directories in that container.
    #
    # There's a 3 process overhead here which is only necessary in bash
    # TODO consider switching this script to python, something faster.
    exec 3>&1
    repo_containers |
        awk -e '/\/$/ { print($0); next; }' \
            -e '{ print $0 | "cat >&3" }' |
        "${batch[@]}" \
            find % -mindepth 1 -maxdepth 1 -type d -print
    exec 3>&-
}

add_subprojects() {
  local it sub_projects
  while read -r it; do
    sub_projects=
    if [ -e "$it/.gitmodules" ]; then
      sub_projects=$(git config --file "$it/.gitmodules" --get-regexp path |
                       cut -d' ' -f 2- |
                       tr '\n' ,)
      sub_projects="${sub_projects/%,/}"
    fi

    if [ -n "$sub_projects" ]; then
      echo "$it,$sub_projects"
    else
      echo "$it"
    fi
  done
}

expand_repos_with_title() {
  awk -F , \
      -v sep="$sep" \
      -v repo_path_aliases="$REPO_PATH_ALIASES" \
      -e 'BEGIN {
  c1 = split(repo_path_aliases, alias_lines, ":")
  for (i = 1; i <= c1; i++) {
    c2 = split(alias_lines[i], alias_record, ",")
    src = alias_record[1]
    dest = alias_record[2]
    aliases[src] = dest;
  }
}' \
      -e 'function basename(path, _repo_segments, _repo_segments_count) {
  _repo_segments_count = split(path, _repo_segments, "/")
  return _repo_segments[_repo_segments_count]
}' \
      -e 'function string_prefix_p(str, prefix) {
  return 1 == index(prefix, substr(str, 0, length(prefix)))
}' \
      -e 'function repo_title(path) {
  for (alias in aliases) {
    if (string_prefix_p(path, alias)) {
      path = substr(path, length(alias))
      # Remove leading / prefix.
      if (substr(path, 0, 1) == "/") {
        path = substr(path, 2)
      }
      # Append aliased prefix.
      if (aliases[alias]) {
        path = aliases[alias] "/" path
      }
      return path
    }
  }
  return basename(path)
}' \
      -e '{
  path = $1
  title = repo_title($1)
  print($1 sep title)
  for (i = 2; i <= NF; i++) {
    print($1 "/" $i sep title "/" $i)
  }
}'
}

# The condition used to check whether a directory {} is a code repository or not.
# this can be any shell expression that can be passed to `find -exec ${repo_assert} ';'`.
repo_assert=( [ -e '{}/.git' -o -e '{}/.sl' -o -e '{}/GemFile' -o -e '{}/.projectile' ] )

# The approach is to spawn a find process for each path that is potentially
# a repository assert a repository test on them and print out when true.
# shellcheck disable=SC2068
maybe_repos |
  "${batch[@]}" \
    find % -mindepth 0 -maxdepth 0 -exec ${repo_assert[@]} ';' -print |
  if [ "$recursive" -eq 1 ]; then add_subprojects; else cat; fi |
  expand_repos_with_title
