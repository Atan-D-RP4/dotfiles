#!/usr/bin/env python3
import argparse
import asyncio
import logging
import os
import pathlib
import shutil
import sys
from typing import (
    Any,
    AsyncIterator,
    Dict,
    Iterable,
    List,
    NamedTuple,
    Optional,
    Union,
)

import asyncinotify as ainotify
from mohkale.torutils import backend, watcher, clients


class _WatcherRecord(NamedTuple):
    """Value type for the items added to the watcher torrent queue."""

    # Download directory (not including watcher sub-directory).
    root: pathlib.Path
    # The newly encountered torrent file.
    file: pathlib.Path
    # The watcher suffix associated with `file`.
    suffix: watcher.WatcherSuffixes


def _find_suffix(file: Union[pathlib.Path, str]) -> Optional[watcher.WatcherSuffixes]:
    """Find watched suffix for `file` if it has it."""
    file = str(file)
    return next(
        (suffix for suffix in watcher.WatcherSuffixes if file.endswith(suffix.value)),
        None,
    )


###############################################################################
#                              Directory Watcher                              #
###############################################################################

# Inotify mask to use when watching for new torrents.
_FILE_WATCHER_MASK = ainotify.Mask.MOVED_TO | ainotify.Mask.CLOSE_WRITE
# Inotify mask to use to recursively add new directories to the watch list.
_DIRECTORY_WATCHER_MASK = ainotify.Mask.CREATE | ainotify.Mask.DELETE


async def _watch_for_torrents(
    config: watcher.WatcherConfig,
    initial_directories: List[pathlib.Path],
) -> AsyncIterator[pathlib.Path]:
    """Create a recursive inotify watcher starting with `initial_directories`."""

    total_mask = _FILE_WATCHER_MASK | _DIRECTORY_WATCHER_MASK

    def _add_new_watcher(
        inotify: ainotify.Inotify, directory: pathlib.Path, mask: ainotify.Mask
    ) -> None:
        try:
            inotify.add_watch(directory, mask)
        except ainotify.InotifyError as ex:
            # The MASK_CREATE mask should prevent this but doesn't. I guess
            # the library supresses the overwriting of the watch but the
            # python wrapper doesn't suppress the exception.
            if "errno 17:" not in str(ex):
                logging.exception(
                    'Encountered libinotify exception when adding watch for directory="%s"',
                    directory,
                )
                # raise ex

    def _on_newdir(
        inotify: ainotify.Inotify, directory: pathlib.Path
    ) -> Iterable[pathlib.Path]:
        """What to do when a new directory is created in a watched directory."""
        local_total_mask = total_mask | ainotify.Mask.MASK_CREATE
        logging.info(
            'Adding watcher for new directory="%s" with mask="%s"',
            directory,
            local_total_mask,
        )
        # There's potential for a race condition here, new files could have been
        # added between when this directory was created and we created a new watcher
        # for it. To work around this we walk this directory immediately after its
        # creation and handle the files and directories as appropriate. This is done
        # after we create the watcher in case the file is created after the watcher
        # but before the walk. Otherwise we just handle it smartly.
        _add_new_watcher(inotify, directory, local_total_mask)
        for root_, directories, files in os.walk(directory):
            root = pathlib.Path(root_)
            for subdir in directories:
                logging.info(
                    'Adding watcher for new directory="%s" with mask="%s"',
                    root / subdir,
                    local_total_mask,
                )
                _add_new_watcher(inotify, root / subdir, local_total_mask)
            yield from (root / file for file in files)

    with ainotify.Inotify() as inotify:
        for directory in initial_directories:
            logging.info(
                'Adding watcher for directory="%s" with mask="%s"',
                directory,
                total_mask,
            )
            inotify.add_watch(directory, total_mask)

        async for event in inotify:
            if event.path is None:
                continue
            if event.mask & ainotify.Mask.IGNORED:
                continue
            if event.path.is_relative_to(config.added_dir):
                logging.info(
                    "Skipping event for file=%s because it's been ignored", event.path
                )
                continue

            if event.mask & ainotify.Mask.ISDIR:
                if event.mask & ainotify.Mask.DELETE:
                    logging.info(
                        'Encountered rmdir event for directory="%s"', event.path
                    )
                    # Note: watch should be removed by an earlier IGNORED event.
                    # inotify.rm_watch(event.watch)
                if event.mask & ainotify.Mask.CREATE:
                    for file_path in _on_newdir(inotify, event.path):
                        yield file_path
            elif event.mask & _FILE_WATCHER_MASK:
                # Some programs seem to call write() even on empty files.
                if (
                    event.mask & ainotify.Mask.CLOSE_WRITE
                    and os.path.getsize(event.path) == 0
                ):
                    # Firefox creates both the final file and the partial download
                    # file at the same time and won't move one to the other until
                    # later.
                    logging.debug(
                        "Skipping event for file=%s because it's empty", event.path
                    )
                    continue

                yield event.path


async def directory_reader(
    config: watcher.WatcherConfig,
    queue: "asyncio.Queue[_WatcherRecord]",
) -> List[pathlib.Path]:
    """Async task to push existing torrent files to `queue`.

    This function will recursively search the watcher root directory for new
    torrent files not already in the added directory and then push them into
    `queue`.

    Parameters
    ----------
    config
        Watcher configuration.
    queue
        Async queue.

    Returns
    -------
    A list of all the non-watch directories that were found while searching the
    watch directory. This should be used to setup inotify watchers for these
    directories.
    """
    directories_to_watch = []

    def _search_watch_directory(
        watch_dir: pathlib.Path,
    ) -> Iterable[pathlib.Path]:
        """Helper to recursively search for files in `watch_dir`."""
        logging.info('Pre-adding existing files in directory="%s"', watch_dir)
        directories_to_watch.append(watch_dir)

        for root_, directories, files in os.walk(watch_dir):
            root = pathlib.Path(root_)

            # Prune out the torrent-added directory.
            if config.added_dir.parent == root:
                directories2 = [d for d in directories if d != config.added_dir.name]
                if len(directories) != len(directories2):
                    logging.debug(
                        'Skipping watching torrent-added directory="%s"',
                        config.added_dir,
                    )
                    directories[:] = directories2

            # Include remaining directories in the to-watch list.
            directories_to_watch.extend(root / directory for directory in directories)

            # Pass back each file to the calling function and let it add to the
            # queue.
            logging.debug('Checking for torrent files in directory="%s"', root)
            for file in files:
                yield root / file

    for config_root in config.download_dirs:
        for file in _search_watch_directory(config_root / config.watch_subdir):
            suffix = _find_suffix(file)
            if suffix is None:
                logging.warning(
                    'Skipping file="%s" because of unknown suffix',
                    file,
                )
                continue

            logging.info('Adding file="%s"', file)
            await queue.put(_WatcherRecord(config_root, file, suffix))

    return directories_to_watch


async def directory_watcher(
    config: watcher.WatcherConfig,
    queue: "asyncio.Queue[_WatcherRecord]",
) -> None:
    """Async task to push new torrent files to `queue`.

    This function will first recursively add all existing torrents to the
    bittorrent queue. Then it will start an inotify watcher which monitors
    for new files in the watcher directory and then adds them to `queue`.

    Parameters
    ----------
    config
        Watcher configuration.
    queue
        Async queue.
    """
    directories_to_watch = await directory_reader(config, queue)

    async for file in _watch_for_torrents(config, directories_to_watch):
        root = next(
            (
                root
                for root in config.download_dirs
                if file.is_relative_to(root / config.watch_subdir)
            ),
            None,
        )
        suffix = _find_suffix(file)

        if suffix is None:
            logging.debug(
                'Skipping file="%s" because of unknown suffix',
                file,
            )
        elif root is None:
            logging.warning(
                'Skipping file="%s" because it is an unknown torrent-directory',
                file,
            )
        else:
            logging.info('Adding file="%s"', file)
            await asyncio.sleep(1)  # In case something is writing the file directly.
            await queue.put(_WatcherRecord(root, file, suffix))


###############################################################################
#                               Daemon Watchers                               #
###############################################################################

async def heartbeat(
    client: clients.TorrentClient,
    alive_event: asyncio.Event,
    check_interval_alive: int,
    check_interval_dead: int,
) -> None:
    """Periodically check daemon is up by sending a heartbeat.

    Parameters
    ----------
    client
        TODO
    alive_event
        Event which is set if the daemon is running.
    check_interval_alive
        Interval to wait between heartbeats if daemons last known status
        was alive.
    check_interval_dead
        Interval to wait between heartbeats if daemons last known status
        was dead.
    """
    logging.info(
        "Starting daemon heartbeat monitor "
        "with alive-interval=%d dead-interval=%d",
        check_interval_alive,
        check_interval_dead,
    )
    first_check = True
    while True:
        alive = await client.is_alive()

        if first_check or alive != alive_event.is_set():
            logging.info(
                ("Daemon is now available" if first_check else "Daemon has come up")
                if alive
                else (
                    "Daemon is not available"
                    if first_check
                    else "Daemon has gone down"
                )
            )
            first_check = False

        if alive:
            alive_event.set()
        else:
            alive_event.clear()
        await asyncio.sleep(check_interval_alive if alive else check_interval_dead)

async def add_torrent(
    client: clients.TorrentClient,
    config: watcher.WatcherConfig,
    file: pathlib.Path,
    suffix: watcher.WatcherSuffixes,
    overrides: Dict[str, Any],
) -> Optional[str]:
    """Add a torrent to daemon asynchronously.

    Returns
    -------
    The hash of the added torrent.
    """
    if suffix == watcher.WatcherSuffixes.TORRENT:
        # The container can't see the file from outside the container.
        # We can either send the base64 encoded torrent-file or simply
        # map it to the path it should be in the container as below.
        file2 = config.remap_for_container(file)
        if file != file2:
            logging.debug(
                "Remapped file=%s to container-file=%s",
                file,
                file2,
            )
        return await client.add_torrent(str(file), str(file2), overrides)

    if suffix == watcher.WatcherSuffixes.MAGNET:
        with file.open("r", encoding="utf-8") as fh:
            magnet_link = fh.read().rstrip()
        return await client.add_magnetlink(magnet_link, overrides)

    logging.error('Failed to add file="%s" with unknown suffix="%s"', file, suffix)
    return None

async def uploader(
    client: clients.TorrentClient,
    config: watcher.WatcherConfig,
    daemon_alive_event: asyncio.Event,
    queue: "asyncio.Queue[_WatcherRecord]",
) -> None:
    """Async task which will continually add files to the daemon.

    This function will repeatedly read files from `queue` and add them to the
    bittorrent daemon. This function will also block if the bittorrent daemon is
    not currently running (based on `daemon_alive_event`).

    Parameters
    ----------
    client
        TODO
    config
        Watcher configuration.
    daemon_alive_event
        Event which is `set` if the transmission daemon is running.
    queue
        Async queue.
    """
    while True:
        root, file, suffix = await queue.get()
        await daemon_alive_event.wait()

        literal_path, overrides = config.calc_overrides(
            file.relative_to(root / config.watch_subdir)
        )
        overrides["download-dir"] = str(
            config.remap_for_container(root / config.incomplete_subdir)
        )

        if not file.exists():
            logging.debug(
                'Skipping adding file="%s" because it no longer exists', file
            )
            continue

        hash_str = await add_torrent(client, config, file, suffix, overrides)
        if hash_str is None:
            continue

        dest = config.added_dir / literal_path.parent / (hash_str + suffix.value)
        logging.info('Moving torrent file="%s" to dest="%s"', file, dest)
        dest.parent.mkdir(parents=True, exist_ok=True)
        if dest.exists():
            logging.warning(
                'New torrent dest="%s" already exists, deleting original file="%s"',
                dest,
                file,
            )
            file.unlink()
        else:
            shutil.move(str(file), dest)


###############################################################################
#                                     TODO                                    #
###############################################################################


def _make_watcher_directories(config: watcher.WatcherConfig) -> bool:
    """Ensure all the directories this script depends on exist."""
    for directory in config.download_dirs:
        directory = directory / config.watch_subdir
        if directory.exists():
            continue

        logging.info('Creating non-existent watcher directory="%s"', directory)
        try:
            directory.mkdir(parents=True, exist_ok=True)
        except OSError:
            logging.exception('Error while creating directory="%s"', directory)
            return False
    return True


async def torwatcher(
    config: watcher.WatcherConfig,
    client: clients.TorrentClient,
    alive_heartbeat_interval: int,
    dead_heartbeat_interval: int,
) -> bool:
    """Main function."""
    # Pre-requisites for watching torrents.
    if not _make_watcher_directories(config):
        return False

    torrent_queue: "asyncio.Queue[_WatcherRecord]" = asyncio.Queue()
    daemon_alive_event = asyncio.Event()

    tasks = []
    tasks.append(asyncio.create_task(directory_watcher(config, torrent_queue)))

    async with client as client:
        tasks.append(
            asyncio.create_task(
                heartbeat(
                    client,
                    daemon_alive_event,
                    alive_heartbeat_interval,
                    dead_heartbeat_interval,
                )
            )
        )
        await uploader(
            client,
            config,
            daemon_alive_event,
            torrent_queue,
        )

    for task in tasks:
        task.cancel()
    await asyncio.gather(*tasks, return_exceptions=True)
    return True  # Should never be reached because this is a daemon


###############################################################################
#                                     Main                                    #
###############################################################################


def _parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-b",
        "--backend",
        default=backend.TorrentBackend.default().name,
        choices=[it.name for it in backend.TorrentBackend],
        help="Specify which torrent backend to retrieve the watcher configuration from.",
    )
    parser.add_argument(
        "-c",
        "--watcher-config",
        help="Config file for the watcher daemon",
    )
    parser.add_argument(
        "-l",
        "--log-level",
        metavar="LEVEL",
        default=logging.INFO,
        type=lambda x: getattr(logging, x.upper()),
        help="verbosity of logging output",
    )
    parser.add_argument(
        "-i",
        "--daemon-alive-heartbeat",
        default=5 * 60,
        metavar="DURATION",
        help="How long to wait between daemon alive "
        "checks when it is known to be alive",
    )
    parser.add_argument(
        "-I",
        "--daemon-dead-heartbeat",
        default=5,
        metavar="DURATION",
        help="How long to wait between daemon " "checks when it is known to be down",
    )

    args = parser.parse_args()

    args.backend = backend.TorrentBackend[args.backend]

    if not args.watcher_config:
        args.watcher_config = watcher.watcher_file(args.backend)

    args.config = watcher.WatcherConfig.from_file(args.watcher_config)
    args.client = args.backend.client()

    return args


def main() -> bool:
    args = _parse_arguments()

    try:
        from mohkale.pylog.config import use_config as use_logging_config
    except ImportError:
        logging.basicConfig(level=args.log_level)
    else:
        use_logging_config("transmission-watcher", level=args.log_level)

    try:
        return asyncio.run(
            torwatcher(
                args.config,
                args.client,
                args.daemon_alive_heartbeat,
                args.daemon_dead_heartbeat,
            )
        )
    except KeyboardInterrupt:
        logging.info("Encountered keyboard interrupt, exiting")
        sys.exit(1)


if __name__ == "__main__":
    sys.exit(0 if main() else 1)
