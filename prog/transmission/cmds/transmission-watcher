#!/usr/bin/env python3
"""
Watch a torrents root directory for new .torrent or .magnet files, automatically
adding them into transmission as they're downloaded.

This script depends on JSON configuration file (mine can be found [[file:~/.dotfiles/programs/transmission/watch.json][here]]), specifying
the general torrent directories and, more importantly, the directory to watch for
torrents. The location of the files is significant. Once the torrents have been added
to transmission they'll be added to a similar path under the added directory. Once the
download completes the torrent will be moved to a similar directory relative to the
root download directory.
"""

import argparse
import asyncio
import enum
import functools
import json
import logging
import os
import pathlib
import sys
from typing import Any, Dict, List, NamedTuple, Optional, Union

import asyncinotify as ainotify

import transmission as t

# Default config file path.
WATCHER_FILE = (
    pathlib.Path(os.environ.get("XDG_CONFIG_HOME", "~/.config")).expanduser()
    / "transmission-daemon"
    / "watcher.json"
)


class WatcherConfig:
    """Transmission watcher configuration.

    Members
    -------
    root
        Root directory for torrent files. Will be watched for new torrents.
    added
        Subdirectory of `root` where torrents will be put after downloading.
    rules
        Collection of rules to set overrides for the torrent-add request based
        on the location in `root` where the file is placed.
    """

    def __init__(self, cfg: dict):
        self.root = pathlib.Path(cfg["torrents-dir"]).expanduser()
        self.added = self.root / cfg["added-subdir"]

        self.added.mkdir(parents=True, exist_ok=True)

        self.rules = [*cfg["rules"]]

    @functools.lru_cache
    def calc_overrides(self, path: pathlib.Path) -> Optional[Dict[str, Any]]:
        """Determine torrent-add request overrides."""
        overrides = {}
        for rule in self.rules:
            if path.parts[0] == rule["directory"]:
                overrides.update(rule["overrides"])
                path = pathlib.Path(*path.parts[1:])
        return path, overrides


class WatcherSuffixes(enum.Enum):
    """Suffixes of files that can be added to Transmission by the watcher."""

    TORRENT = ".torrent"
    MAGNET = ".magnet"


class _WatcherRecord(NamedTuple):
    """Value type for the items aadded to the watcher torrent queue."""

    file: pathlib.Path
    suffix: WatcherSuffixes


def _find_suffix(file: Union[pathlib.Path, str]) -> Optional[WatcherSuffixes]:
    """Find watched suffix for `file` if it has it."""
    file = str(file)
    return next(
        (suffix for suffix in WatcherSuffixes if file.endswith(suffix.value)),
        None,
    )


async def _watch_for_torrents(initial_directories: List[pathlib.Path]) -> None:
    """Create a recursive inotify watcher starting with `initial_directories`."""
    # Inotify mask to use when watching for new torrents.
    FILE_WATCHER_MASK = ainotify.Mask.MOVED_TO | ainotify.Mask.CREATE
    # Inotify mask to use to recursively add new directories to the watch list.
    DIRECTORY_WATCHER_MASK = ainotify.Mask.CREATE | ainotify.Mask.DELETE
    TOTAL_MASK = FILE_WATCHER_MASK | DIRECTORY_WATCHER_MASK

    def _add_new_watcher(
        inotify: ainotify.Inotify, directory: pathlib.Path, mask: ainotify.Mask
    ) -> bool:
        try:
            inotify.add_watch(directory, mask)
        except ainotify.InotifyError as ex:
            # The MASK_CREATE mask should prevent this but doesn't. I guess
            # the library supresses the overwriting of the watch but the
            # python wrapper doesn't suppress the exception.
            if "errno 17:" not in str(ex):
                logging.exception(
                    'Encountered libinotify exception when adding watch for directory="%s"',
                    directory,
                )
                # raise ex

    def _on_newdir(inotify: ainotify.Inotify, directory: pathlib.Path) -> None:
        local_total_mask = TOTAL_MASK | ainotify.Mask.MASK_CREATE
        logging.info(
            'Adding watcher for new directory="%s" with mask="%s"',
            directory,
            local_total_mask,
        )
        # There's potential for a race condition here, new files could have been
        # added between when this directory was created and we created a new watcher
        # for it. To work around this we walk this directory immediately after its
        # creation and handle the files and directories as appropriate. This is done
        # after we create the watcher in case the file is created after the watcher
        # but before the walk. Otherwise we just handle it smartly.
        _add_new_watcher(inotify, directory, local_total_mask)
        for root, directories, files in os.walk(directory):
            root = pathlib.Path(root)
            for subdir in directories:
                logging.info(
                    'Adding watcher for new directory="%s" with mask="%s"',
                    root / subdir,
                    local_total_mask,
                )
                _add_new_watcher(inotify, root / subdir, local_total_mask)
            yield from (root / file for file in files)

    logging.info(
        'Starting watcher for directory="%s" with mask=%s',
        initial_directories[0],
        TOTAL_MASK,
    )
    with ainotify.Inotify() as inotify:
        for directory in initial_directories:
            logging.debug(
                'Adding watcher for directory="%s" with mask="%s"',
                directory,
                TOTAL_MASK,
            )
            inotify.add_watch(directory, TOTAL_MASK)

        async for event in inotify:
            if event.mask & ainotify.Mask.IGNORED:
                continue

            if event.mask & ainotify.Mask.ISDIR:
                if event.mask & ainotify.Mask.DELETE:
                    logging.info(
                        'Encountered rmdir event for directory="%s"', event.path
                    )
                    # Note: watch should be removed by an earlier IGNORED event.
                    # inotify.rm_watch(event.watch)
                if event.mask & ainotify.Mask.CREATE:
                    for file_path in _on_newdir(inotify, event.path):
                        yield file_path
            elif event.mask & FILE_WATCHER_MASK:
                yield event.path


async def directory_reader(
    config: WatcherConfig,
    queue: "asyncio.Queue[_WatcherRecord]",
) -> List[pathlib.Path]:
    """Async task to push existing torrent files to `queue`.

    This function will recursively search the watcher root directory for new
    torrent files not already in the added directory and then push them into
    `queue`.

    Parameters
    ----------
    config
        Transmission watcher configuration.
    queue
        Async queue.
    """
    logging.info('Pre-adding existing files in directory="%s"', config.root)

    directories_to_watch = [config.root]

    for root, directories, files in os.walk(config.root):
        root = pathlib.Path(root)
        root_relative = root.relative_to(config.root)

        # Prune out added torrent directories.
        added_directories = {
            d for d in directories if (root / d).is_relative_to(config.added)
        }
        for directory in added_directories:
            logging.debug(
                'Skipping watching added directory="%s"',
                (root / directory).relative_to(config.added),
            )
        directories[:] = [d for d in directories if d not in added_directories]
        # Include remaining directories in to-watch list.
        for directory in directories:
            directories_to_watch.append(root / directory)

        logging.debug('Checking for torrent files in directory="%s"', root)
        for file in files:
            suffix = _find_suffix(file)
            if suffix is None:
                logging.warning(
                    'Skipping file="%s" because of unknown suffix', root_relative / file
                )
            else:
                logging.info('Adding file="%s"', root_relative / file)
                await queue.put(_WatcherRecord(root / file, suffix))

    return directories_to_watch


async def directory_watcher(
    config: WatcherConfig,
    queue: "asyncio.Queue[_WatcherRecord]",
) -> None:
    """Async task to push new torrent files to `queue`.

    This function will first recursively add all existing torrents to the
    Transmission queue. Then it will start an inotify watcher which monitors
    for new files in the watcher directory and then adds them to `queue`.

    Parameters
    ----------
    config
        Transmission watcher configuration.
    queue
        Async queue.
    """
    directories_to_watch = await directory_reader(config, queue)

    async for path in _watch_for_torrents(directories_to_watch):
        suffix = _find_suffix(path)

        if suffix is not None:
            logging.info('Adding file="%s"', path.relative_to(config.root))
            await asyncio.sleep(1)  # In case something is writing the file directly.
            await queue.put(_WatcherRecord(path, suffix))
        else:
            logging.debug(
                'Skipping file="%s" because of unknown suffix',
                path.relative_to(config.root),
            )


async def transmission_heartbeat(
    transmission: t.AsyncTransmission,
    alive_event: asyncio.Event,
    check_interval_alive: int,
    check_interval_dead: int,
) -> None:
    """Periodically check Transmission is up by sending a heartbeat.

    Parameters
    ----------
    transmission
        Transmission client.
    alive_event
        Event which is set if the daemon is running.
    check_interval_alive
        Interval to wait between heartbeats if Transmissions last known status
        was alive.
    check_interval_dead
        Interval to wait between heartbeats if Transmissions last known status
        was dead.
    """
    logging.info(
        "Starting transmission heartbeat monitor for host=%s "
        "port=%d with alive-interval=%d dead-interval=%d",
        transmission.host,
        transmission.port,
        check_interval_alive,
        check_interval_dead,
    )
    first_check = True
    while True:
        alive = await transmission.acheck()

        if first_check or alive != alive_event.is_set():
            logging.info(
                (
                    "Transmission daemon is available at host=%s port=%d"
                    if first_check
                    else "Transmission daemon has come up at host=%s port=%d"
                )
                if alive
                else (
                    "Transmission daemon is not available at host=%s port=%d"
                    if first_check
                    else "Transmission daemon has gone down from host=%s port=%d"
                ),
                transmission.host,
                transmission.port,
            )
            first_check = False

        if alive:
            alive_event.set()
        else:
            alive_event.clear()
        await asyncio.sleep(check_interval_alive if alive else check_interval_dead)


@t.retry(5)
async def _add_torrent(
    transmission: t.AsyncTransmission,
    url_or_magnetlink: str,
    overrides: Dict[str, any],
):
    """Add a torrent to Transmission asynchronously."""
    resp = await transmission.acommand(
        "torrent-add",
        filename=url_or_magnetlink,
        **overrides,
    )
    if resp["result"] != "success":
        raise t.StatusException("Encountered non-sucess status")
    args = resp["arguments"]
    key = "torrent-duplicate" if "torrent-duplicate" in args else "torrent-added"
    return args[key]["hashString"]


async def transmission_uploader(
    config: WatcherConfig,
    transmission: t.AsyncTransmission,
    transmission_alive_event: asyncio.Event,
    queue: "asyncio.Queue[_WatcherRecord]",
) -> None:
    """Async task which will continually add files to Transmission.

    This function will repeatedly read files from `queue` and add them to the
    Transmission daemon. This function will also block if the transmission
    daemon is not currently running (based on `transmission_alive_event`).

    Parameters
    ----------
    config
        Transmission watcher configuration.
    transmission
        Transmission client.
    transmission_alive_event
        Event which is `set` if the transmission daemon is running.
    queue
        Async queue.
    """
    while True:
        file, suffix = await queue.get()
        await transmission_alive_event.wait()

        literal_path, overrides = config.calc_overrides(file.relative_to(config.root))

        if not file.exists():
            logging.debug('Skipping adding file="%s" because it no longer exists', file)
            continue

        # Add file to transmission based on its suffix.
        try:
            if suffix == WatcherSuffixes.TORRENT:
                hash_str = await _add_torrent(transmission, str(file), overrides)
            elif suffix == WatcherSuffixes.MAGNET:
                with file.open("r", encoding="utf-8") as fh:
                    magnet_link = fh.read().rstrip()
                hash_str = await _add_torrent(transmission, magnet_link, overrides)
            else:
                logging.error(
                    'Failed to add file="%s" with unknown suffix="%s"', file, suffix
                )
                continue
        except t.StatusException:
            logging.exception('Failed to add file="%s"', file)
            continue

        # Move file after succesfully adding to Transmission.
        dest = config.added / literal_path.parent / (hash_str + suffix.value)
        logging.info('Moving torrent file="%s" to dest="%s"', file, dest)
        dest.parent.mkdir(parents=True, exist_ok=True)
        if dest.exists():
            logging.warning(
                'New torrent dest="%s" already exists, deleting original file="%s"',
                dest,
                file,
            )
            file.unlink()
        else:
            file.rename(dest)


async def main(
    config: WatcherConfig,
    transmission: t.AsyncTransmission,
    alive_heartbeat_interval: int,
    dead_heartbeat_interval: int,
) -> bool:
    """Main function."""
    torrent_queue: "asyncio.Queue[_WatcherRecord]" = asyncio.Queue()
    transmission_alive_event = asyncio.Event()

    tasks = []
    tasks.append(asyncio.create_task(directory_watcher(config, torrent_queue)))

    # KLUDGE: Need to enter in async context to get async session.
    async with transmission as transmission:
        tasks.append(
            asyncio.create_task(
                transmission_heartbeat(
                    transmission,
                    transmission_alive_event,
                    alive_heartbeat_interval,
                    dead_heartbeat_interval,
                )
            )
        )
        await transmission_uploader(
            config, transmission, transmission_alive_event, torrent_queue
        )

    for task in tasks:
        task.cancel()
    await asyncio.gather(*tasks, return_exceptions=True)


def _parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-c",
        "--config",
        default=WATCHER_FILE,
        help="Config file for the watcher daemon",
    )
    parser.add_argument(
        "-t",
        "--transmission-config",
        metavar="FILE",
        default=t.CONFIG_FILE,
        type=pathlib.Path,
        help="transmission watcher configuration file",
    )
    parser.add_argument(
        "-l",
        "--log-level",
        metavar="LEVEL",
        type=lambda x: getattr(logging, x.upper()),
        help="verbosity of logging output",
    )
    parser.add_argument(
        "-i",
        "--transmission-alive-heartbeat",
        default=5 * 60,
        metavar="DURATION",
        help="How long to wait between transmission daemon "
        "checks when its known to be alive",
    )
    parser.add_argument(
        "-I",
        "--transmission-dead-heartbeat",
        default=5,
        metavar="DURATION",
        help="How long to wait between transmission daemon "
        "checks when its known to be down",
    )

    args = parser.parse_args()

    with args.config.open("r", encoding="utf-8") as config_fh:
        args.config = WatcherConfig(json.load(config_fh))
    args.connection = t.AsyncTransmission.from_conf_file(args.transmission_config)

    return args


if __name__ == "__main__":
    args = _parse_arguments()

    try:
        from mohkale.pylog.config import use_config as use_logging_config
    except ImportError:
        logging.basicConfig(level=args.log_level)
    else:
        use_logging_config("transmission-watcher", level=args.log_level)

    try:
        asyncio.run(
            main(
                args.config,
                args.connection,
                args.transmission_alive_heartbeat,
                args.transmission_dead_heartbeat,
            )
        )
    except KeyboardInterrupt:
        logging.info("Encountered keyboard interrupt, exiting")
        sys.exit(1)
